
<html>
<body>
<p>Moreover, the application of data mining to the cases base allowed the specification of rules to settle relationships among the stored cases with the aim of inferring possible causes of error in the domains classification. In this way, a learning mechanism was designed to update the knowledge base and thus improve the already made classification as regards the values assigned to the discriminating function.</p>
<p>The selection mechanism designed using data-mining techniques is feasible to be implemented by means of agents technology. For this purpose, the roles required to operate the system have been identified (Jennings, 2000), and each of them was assigned to be under the responsibility of different software agents. Mobile agents take consults to the domains identified by an intelligent agent called a router agent. This agent is responsible for the classification and learning mechanism designed in this work. </p>
<p>In this way, it has been possible to design an agent-based architecture of a dynamic DSS that satisfies the main functionality specified for this system, i.e., to guide information requirements from users to the domains that offer the greatest possibility of answering them.</p>
<center><b>REFERENCES<br/></b></center>
    <p>Cabral, L., Caliusco, M., Nissio, H., Villarreal, M., Galli, P., Taverna, M., &amp; Chiotti, O.(2000). Use of agents technology to support distributed decision processes. In J.A. Dominguez Machuca &amp; T. Mandakovic (Eds.), <i>Proceedings of</i> <i>the First World Conference on Production and Operations Management, POM</i> <i>Sevilla 2000</i>. Sevilla, Spain, August , pp.1-10, Paper 2071.</p>
    <p>Dingsoyr, T. (1998). Integration of data mining and case-based reasoning. Available online at &lt;http://www.idi.ntnu.no/~dingsoyr/diploma&gt;.Jennings, N. (2001). An agent-based approach for building complex software systems. <i>Communications of the ACM</i>, 44 (4), 35-42. </p>
<p>Kachigan, S. K. (1991). Multivariable statistical analysis. A conceptual introduction.New York: Radius Press.</p>
<p>Rodriguez, F., Ramos, C., &amp; Henriques, P. (2000). A case-based reasoning framework to extract knowledge from data. In N. Ebecken &amp; C.A. Brebbia (eds.) <i>Data Mining II</i>.Southampton, Boston, MA:WIT Press.</p>
<p>Ruiz, C., Fisler, K., & Cole, C. (2000). “KDDRG – Data mining for software engineering”.
Available online at: &lt;http://www.cs.wpi.edu/~ruiz/KDDRG/dm_for_se.html &gt;.<br/></p>
<p>Rus, D., Gray, R., &amp; Kots, D. (1998). Transportable information agents. In M. Huhns &amp;M. Singh (Eds.). <i>Reading in Agents</i>. San Francisco, CA: Morgan Kaufmann Publishers, Inc., pp. 283-291.</p>
<p>Saaty, T.L. (1980). <i>The analytical hierarchy process</i>. New York: McGraw-Hill.</p>
    <p>Shen, W. & Norrie, D.H. (1999). Agent-based systems for intelligent manufacturing: A
state-of-the-art survey. Knowledge and Information Systems, 1 (2), 129-156.<p>
        <p>Stegmayer, G., Taverna, M.L., Chiotti, O., & Galli, M.R. (2001). The agent routering
process of dynamic distributed decision support system. Journal of Computer
Science & Technology, 2 (5), 30-43. Available online at:  &lt;http://journal.info.unlp.edu.ar&gt;.</p>
</p>

<center><p><b>Chapter XX<br/></b></p>
<p><b>Critical and Future Trendsin Data Mining:A Review of Key Data Mining Technologies/Applications</b></p>
<p>Jeffrey Hsu<br/></p>
<p>Fairleigh Dickinson University, USA<br/></p>
<p><b>ABSTRACT<br/></b></p></center>
    <p><i>Every day, enormous amounts of information are generated from all sectors, whether it be business, education, the scientific community, the World Wide Web (WWW), or one of many readily available off-line and online data sources. From all of this, which represents a sizable repository of data and information, it is possible to generate worthwhile and usable knowledge. As a result, the field of Data Mining (DM) and knowledge discovery in databases (KDD) has grown in leaps and bounds and has shown great potential for the future (Han  & Kamber, 2001). The purpose of this chapter is to survey many of the critical and future trends in the field of DM, with a focus on those which are thought to have the most promise and applicability to future DM applications.<br/></i></p>
<center><p><b>MAJOR TRENDS IN TECHNOLOGIES AND METHODS: WEB MINING</b></p></center>
<p>Web mining is one of the most promising areas in DM, because the Internet and WWW are dynamic sources of information. Web mining is the extraction of interesting and potentially useful patterns and implicit information from artifacts or activity related to the WWW (Etzioni, 1996). The main tasks that comprise Web mining include retrieving Web documents, selection and processing of Web information, pattern discovery in sites and across sites, and analysis of the patterns found (Garofalis, Rastogi, Seshadri Shim,& 1999; Kosala & Blockeel, 2000; Han, Zaiane, Chee,& Chiang, 2000).<br/></p>
<p>Web mining can be categorized into three separate areas: web-content mining, Web-structure mining, and Web-usage mining. Web-content mining is the process of extracting knowledge from the content of documents or their descriptions. This includes the mining of Web text documents, which is a form of resource discovery based on the indexing of concepts, sometimes using agent-based technology. Web-structure mining is the process of inferring knowledge from the links and organizations in the WWW.Finally, Web-usage mining, also known as Web-log mining, is the process of extracting interesting patterns in Web-access logs and other Web-usage information (Borges & Levene, 1999; Kosala & Blockeel, 2000; Madria, Bhowmick, Ng, & Lim, 1999).<br/></p>
<p><i>Web-content mining</i> is concerned with the discovery of new information and knowledge from web-based data, documents, and pages. According to Kosala and Blockeel (2000), there are two main approaches to Web-content mining: an information retrieval view and a database (DB) view. The information retrieval view is designed to work with both unstructured (free text, such as news stories) or semistructured documents (with both HTML and hyperlinked data), and attempts to identify patterns and models based on an analysis of the documents, using such techniques as clustering, classification, finding text patterns, and extraction rules (Billsus & Pazzani, 1999; Frank, Paynter, Witten, Gutwin & Nevill-Manning, 1998; Nahm &amp; Mooney, 2000). The other main approach, which is to content mine semi-structured documents, uses many of the same techniques as used for unstructured documents, but with the added complexity and challenge of analyzing documents containing a variety of media elements (Crimmins & Smeator, 1999; Shavlik  & Elassi-Rad, 1998).<br/></p>
<p>There are also applications that focus on the design of languages, which provide better querying of DBs containing web-based data. Researchers have developed many <i>web-oriented query languages</i> that attempt to extend standard DB query languages such as SQL to collect data from the WWW, e.g., WebLog and WebSQL. The TSIMMIS system (Chawathe et al., 1994) extracts data from heterogeneous and semistructured information sources and correlates them to generate an integrated DB representation of the extracted information (Maarek & Ben Shaul, 1996; Han, 1996; Meldelzon, Mihaila, & Milo, 1996; Merialdo, Atzeni, &amp; Mecca, 1997).</p>
<p>Other applications focus on the building and management of<i>multilevel or multi-layered DBs</i>. This suggests a multilevel-DB approach to organizing web-based information. The main idea behind this method is that the lowest level of the DB contains primitive semistructured information stored in various Web repositories, such as hypertext documents. At the higher level(s), metadata or generalizations are extracted from lower levels and organized in structured collections such as relational or object-oriented DBs.Kholsa, Kuhn, and Soparkar (1996) and King and Novak (1996) have done research in this area.<br/></p>
<p><i>Web-structure mining</i>. Instead of looking at the text and data on the pages themselves, Web-structure mining has as its goal the mining of knowledge from the structure of websites. More specifically, it attempts to examine the structures that exist between documents on a website, such as hyperlinks and other linkages. For instance, links pointing to a document indicate the popularity of the document, while links coming out of a document indicate the richness or perhaps the variety of topics covered in the document. The PageRank (Brin &amp; Page, 1998) and CLEVER (Chakrabarti et al., 1999) methods take advantage of the information conveyed by the links to find pertinent Web pages. Counters of hyperlinks, into and out of documents, retrace the structure of the Web artifacts summarized.<br/></p>
<p><i>Web-usage mining</i>. Yet another major area in the broad spectrum of Web mining is Web-usage mining. Rather than looking at the content pages or the underlying structure,Web-usage mining is focused on Web user behavior or, more specifically, modeling and predicting how a user will use and interact with the Web. In general, this form of mining examines secondary data, or the data that are derived from the interaction of users (Chen, Park, &amp; Yu, 1996). There are two main thrusts in Web-usage mining: general access pattern tracking and customized-usage tracking. General access-pattern tracking analyzes Web logs in order to better understand access patterns and trends. Customized usage tracking analyzes individual trends. Its purpose is to customize websites to users. The information displayed, the depth of the site structure, and the format of the resources can all be dynamically customized for each user over time, based on their patterns of access (Kosala &amp; Blockeel, 2000).<br/></p>
<p>Srivastava, Cooley, Deshpe, and Tan<i>.</i> (2000) have produced a taxonomy of different Web-mining applications and have categorized them into the following types:<i>&#8226; Personalization</i>. The goal here is to produce a more &#8220;individualized&#8221; experience<br/></p>
<p>for a Web visitor, including making recommendations about other pages to visit based on the pages he/she has visited previously.<br/></p>
<p><i>&#8226; System improvement</i>. Performance and speed have always been important factors when it comes to computing systems, and through Web-usage data, it is possible to improve system performance by creating policies and using such methods as load-balancing, Web caching and network transmission.<br/></p>
<p><i>&#8226; Site modification</i>. It is also possible to modify aspects of a site based on user patterns and behavior. After a detailed analysis of a user&#8217;s activities on a site, it is possible to make design changes and structural modifications to site to enhance a user&#8217;s satisfaction and the site&#8217;s usability.<br/></p>
<p><i>&#8226; Business intelligence</i>. Another important application of Web-usage mining is the ability to mine for marketing intelligence information. Buchner and Mulvenna.(1998) used a data hypercube to consolidate Web-usage data together with marketing data to obtain insights with regards to e-commerce.<br/></p>
<p><i>&#8226; Usage characterization</i>. There is a close relationship between DM of Web-usage data and Web-usage characterization research. This area is focused more on such topics as interaction with the browser interface, navigational strategies, the occurrence of certain types of activities, and models of Web usage. Studies in this area include Catledge and Pitkow (1995), Doorenbos, Etzioni, and Weld (1996), and Arlitt and Williamson (1997).<br/></p>
<p>Yet another area that has been gaining interest is agent-based approaches. Agentsare intelligent software components that &#8220;crawl through&#8221; the Internet and collect useful information, much like the way a virus-like worm moves through systems wreaking havoc. Generally, agent-based Web-mining systems can be placed into three main categories:information categorization and filtering, intelligent search agents, and personal agents.<br/></p>
<p><i>Information filtering/categorization</i> agents try to automatically retrieve, filter, and categorize discovered information by using various information-retrieval techniques. Agents that can be classified in this category include HyPursuit (Weiss et al., 1996) and Bookmark Organizer (BO). <i>Intelligent search agents</i> search the Internet for relevant information and use characteristics of a particular domain to organize and interpret the discovered information. Some of the better known include ParaSite, and FAQ-Finder.<i>Personalized Web agents</i> try to obtain or learn user preferences and discover Web information sources that correspond to these preferences, and possibly those of other individuals with similar interests, using collaborative filtering. Systems in this class include Netperceptions, WebWatcher (Armstrong, Freitag, Joachims, &amp; Mitchell, 1995), and Syskill &amp; Webert (Pazzani, Muramatsu &amp; Billsus, 1996).</p>
<center><p><b>TEXT DATA MINING (TDM)<br/></b></p></center>
    <p>The possibilities for DM from textual information are largely untapped, making it a fertile area of future research. Text expresses a vast, rich range of information, but in its original, raw form is difficult to analyze or mine automatically.  TDM has relatively fewer research projects and commercial products compared to other DM areas. As expected, TDM is a natural extension of traditional DM, as well as information archeology (Brachman et al., 1993). While most standard DM applications tend to be automated discovery of trends and patterns across large DBs and data sets, in the case of text mining, the goal is to look for pattern and trends, like nuggets of data in large amounts of text (Hearst, 1999).</p>
<p><b>Benefits of TDM<br/></b></p>
    <p>It is important to differentiate between TDM and information access (or information retrieval, as it is better known). The goal of information access is to help users find documents that satisfy their information needs (Baeza-Yates &amp; Ribeiro-Neto, 1999). Text mining focuses on how to use a body of textual information as a large knowledge base rom which one can extract new, never-before encountered information (Craven, DiPasquo, Freitag, McCallum, Mitchell, Nigam &amp; Slattery, 1998). However, the results of certain types of text processing can yield tools that indirectly aid in the information-access process. Examples include text clustering to create thematic overviews of text collections (Rennison, 1994; Wise, Thomas, Pennock, Lantrip, Pottier, &amp; Schur, 1995), automatically generating term associations to aid in query expansion (Voorhees, 1994; Xu &amp; Croft, 1996), and using co-citation analysis to find general topics within a collection or identify central Web pages (Hearst, 1999; Kleinberg, 1998; Larson, 1996;).</p>
<p><b>Methods of TDM<br/></b></p>
    <p>Some of the major methods of TDM include feature extraction, clustering, and categorization. Feature extraction, which is the mining of text within a document, attempts</p>
</body>
</html>